# Classification

## Important topics:

* Logistic Regression
* Loss functions
* Cost functions
* Gradient descent
* Multiclass Classification
* Activation functions:
    * Sigmoid
    * Tanh
    * ReLu
    * Softmax
* One-hot-encoding/decoding
* Pickle

## Resources:

* [DeepAI series: Intro to neural networks](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0 "DeepAI series: Intro to neural networks")
* [DeepAI series: Optimizing deep nerual networks](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc "DeepAI series: Optimizing deep nerual networks")
* [Activation functions](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6 "Activation functions")
    * [Softmax activation](https://www.python-course.eu/softmax.php "Softmax activation")
* [Neural network initialization](https://towardsdatascience.com/random-initialization-for-neural-networks-a-thing-of-the-past-bfcdd806bf9e "Neural network initialization")
* [Cross Entropy](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy "Cross Entropy")
